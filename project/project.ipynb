{
 "cells": [
  {
   "cell_type": "code",
   "id": "91bdfad3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T04:48:00.573301Z",
     "start_time": "2025-12-04T04:47:56.199892Z"
    }
   },
   "source": [
    "import os\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import databento as db\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 4)\n",
    "plt.rcParams[\"axes.grid\"] = True"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "11b4f911",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T04:48:00.585699Z",
     "start_time": "2025-12-04T04:48:00.581365Z"
    }
   },
   "source": [
    "# ========= CONFIG =========\n",
    "\n",
    "@dataclass\n",
    "class ProjectConfig:\n",
    "    dataset: str = \"GLBX.MDP3\"\n",
    "    continuous_symbol: str = \"ES.c.0\"  # front ES continuous future on CME Globex\n",
    "    start_date: str = \"2019-01-01\"\n",
    "    end_date: str = \"2024-12-31\"\n",
    "    event_window_k: int = 5          # +/- k days around rebalance\n",
    "    strat_k_entry: int = 3           # enter k days before rebalance\n",
    "    contract_multiplier: int = 50    # ES multiplier: $50 per index point\n",
    "    rebalance_csv_path: str = \"rebalance_events.csv\"  # you create this\n",
    "\n",
    "CFG = ProjectConfig()"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "40152096",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T04:48:00.675096Z",
     "start_time": "2025-12-04T04:48:00.672983Z"
    }
   },
   "source": [
    "# ========= DATABENTO CLIENT =========\n",
    "\n",
    "def get_db_client() -> db.Historical:\n",
    "    \"\"\"\n",
    "    Create a Databento Historical client.\n",
    "    Uses DATABENTO_API_KEY from environment if present.\n",
    "    \"\"\"\n",
    "    key = \"db-YAMakFGLD6VHUbUnFDmD4AKYSyAch\"\n",
    "    if key:\n",
    "        return db.Historical(key)\n",
    "    return db.Historical()\n",
    "\n",
    "client = get_db_client()"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "f799030a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T04:49:24.688226Z",
     "start_time": "2025-12-04T04:48:00.684839Z"
    }
   },
   "source": [
    "def get_es_continuous_ohlcv(\n",
    "    start: str,\n",
    "    end: str,\n",
    "    dataset: str = CFG.dataset,\n",
    "    continuous_symbol: str = CFG.continuous_symbol,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Fetch daily OHLCV for ES continuous front-month future from Databento.\n",
    "    Uses ohlcv-1d schema and 'continuous' symbology.\n",
    "    Returns a DataFrame indexed by date (naive), with columns: open, high, low, close, volume.\n",
    "    \"\"\"\n",
    "    data = client.timeseries.get_range(\n",
    "        dataset=dataset,\n",
    "        schema=\"ohlcv-1d\",\n",
    "        symbols=continuous_symbol,\n",
    "        stype_in=\"continuous\",\n",
    "        start=start,\n",
    "        end=end,\n",
    "    )\n",
    "    df = data.to_df().copy()\n",
    "\n",
    "    # Ensure datetime index and then convert to naive date index\n",
    "    if not isinstance(df.index, pd.DatetimeIndex):\n",
    "        df.index = pd.to_datetime(df.index)\n",
    "    if df.index.tz is not None:\n",
    "        df.index = df.index.tz_convert(\"UTC\").tz_localize(None)\n",
    "\n",
    "    # If Databento gives one row per day, this is enough; if multiple, keep last per calendar day.\n",
    "    df[\"date\"] = df.index.date\n",
    "    df = (\n",
    "        df.groupby(\"date\")\n",
    "        .agg({\"open\": \"first\", \"high\": \"max\", \"low\": \"min\", \"close\": \"last\", \"volume\": \"sum\"})\n",
    "        .rename_axis(\"date\")\n",
    "    )\n",
    "\n",
    "    return df[[\"open\", \"high\", \"low\", \"close\", \"volume\"]]\n",
    "\n",
    "\n",
    "es_df = get_es_continuous_ohlcv(CFG.start_date, CFG.end_date)\n",
    "es_df.head()\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p2/09s9fm497ql1r7hkb3d2cbwc0000gp/T/ipykernel_66574/232786595.py:12: BentoWarning: The streaming request contained one or more days which have reduced quality: 2019-01-15 (degraded), 2019-02-22 (degraded), 2019-03-13 (degraded)... See: https://databento.com/docs/api-reference-historical/metadata/metadata-get-dataset-condition\n",
      "  data = client.timeseries.get_range(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "               open     high      low    close   volume\n",
       "date                                                   \n",
       "2019-01-01  2508.00  2521.00  2506.25  2517.00    14934\n",
       "2019-01-02  2517.25  2521.25  2452.25  2474.75  1933580\n",
       "2019-01-03  2475.00  2493.50  2443.25  2449.50  2172622\n",
       "2019-01-04  2449.25  2539.25  2438.50  2529.50  2255998\n",
       "2019-01-06  2537.25  2538.75  2532.50  2538.25    15496"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-01</th>\n",
       "      <td>2508.00</td>\n",
       "      <td>2521.00</td>\n",
       "      <td>2506.25</td>\n",
       "      <td>2517.00</td>\n",
       "      <td>14934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-02</th>\n",
       "      <td>2517.25</td>\n",
       "      <td>2521.25</td>\n",
       "      <td>2452.25</td>\n",
       "      <td>2474.75</td>\n",
       "      <td>1933580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-03</th>\n",
       "      <td>2475.00</td>\n",
       "      <td>2493.50</td>\n",
       "      <td>2443.25</td>\n",
       "      <td>2449.50</td>\n",
       "      <td>2172622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-04</th>\n",
       "      <td>2449.25</td>\n",
       "      <td>2539.25</td>\n",
       "      <td>2438.50</td>\n",
       "      <td>2529.50</td>\n",
       "      <td>2255998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-06</th>\n",
       "      <td>2537.25</td>\n",
       "      <td>2538.75</td>\n",
       "      <td>2532.50</td>\n",
       "      <td>2538.25</td>\n",
       "      <td>15496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "aaa913ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T04:49:24.735899Z",
     "start_time": "2025-12-04T04:49:24.727371Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from pandas.tseries.offsets import WeekOfMonth\n",
    "\n",
    "# ========= 1. Load rebalance events =========\n",
    "\n",
    "def sp500_quarterly_rebalance_dates(start_year: int, end_year: int) -> pd.DatetimeIndex:\n",
    "    \"\"\"\n",
    "    Approximate S&P 500 scheduled rebalance dates as the\n",
    "    third Friday of March, June, September, and December\n",
    "    for each year in [start_year, end_year].\n",
    "\n",
    "    Returns a DatetimeIndex of those dates.\n",
    "    \"\"\"\n",
    "    dates = []\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        for month in [3, 6, 9, 12]:\n",
    "            # Third Friday:\n",
    "            #   WeekOfMonth(week=2, weekday=4)\n",
    "            #   - weekday=4 means Friday (0=Mon,...,4=Fri)\n",
    "            #   - week=2 means \"third\" occurrence (0=first,1=second,2=third)\n",
    "            base = pd.Timestamp(year=year, month=month, day=1)\n",
    "            d = base + WeekOfMonth(week=2, weekday=4)\n",
    "            dates.append(d)\n",
    "    return pd.DatetimeIndex(dates).sort_values()\n",
    "\n",
    "# Build rebalance dates matching your ES sample\n",
    "rebalance_dates = sp500_quarterly_rebalance_dates(2019, 2024)\n",
    "\n",
    "rebalance_dates"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2019-03-15', '2019-06-21', '2019-09-20', '2019-12-20',\n",
       "               '2020-03-20', '2020-06-19', '2020-09-18', '2020-12-18',\n",
       "               '2021-03-19', '2021-06-18', '2021-09-17', '2021-12-17',\n",
       "               '2022-03-18', '2022-06-17', '2022-09-16', '2022-12-16',\n",
       "               '2023-03-17', '2023-06-16', '2023-09-15', '2023-12-15',\n",
       "               '2024-03-15', '2024-06-21', '2024-09-20', '2024-12-20'],\n",
       "              dtype='datetime64[ns]', freq=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "86369aa7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T04:49:24.831247Z",
     "start_time": "2025-12-04T04:49:24.826421Z"
    }
   },
   "source": [
    "events_df = pd.DataFrame({\n",
    "    \"event_date\": rebalance_dates.date  # store as date, not full timestamp\n",
    "})\n",
    "\n",
    "events_df = events_df.sort_values(\"event_date\").reset_index(drop=True)\n",
    "events_df.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   event_date\n",
       "0  2019-03-15\n",
       "1  2019-06-21\n",
       "2  2019-09-20\n",
       "3  2019-12-20\n",
       "4  2020-03-20"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-03-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-06-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-09-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-12-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-03-20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "ffa879fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T04:49:25.252492Z",
     "start_time": "2025-12-04T04:49:24.864225Z"
    }
   },
   "source": [
    "# ========= 2. Load S&P 500 weights (daily, 2019–2024) =========\n",
    "\n",
    "weights_df = pd.read_csv(\"sp500_weights_2019_2024.csv\", parse_dates=[\"date\"])\n",
    "weights_df[\"date\"] = weights_df[\"date\"].dt.date   # make comparable with event_date\n",
    "weights_df.head()"
   ],
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'sp500_weights_2019_2024.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# ========= 2. Load S&P 500 weights (daily, 2019–2024) =========\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m weights_df \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43msp500_weights_2019_2024.csv\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparse_dates\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdate\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m weights_df[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdate\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m weights_df[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdate\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mdt\u001B[38;5;241m.\u001B[39mdate   \u001B[38;5;66;03m# make comparable with event_date\u001B[39;00m\n\u001B[1;32m      5\u001B[0m weights_df\u001B[38;5;241m.\u001B[39mhead()\n",
      "File \u001B[0;32m/Library/Python/3.9/site-packages/pandas/io/parsers/readers.py:1026\u001B[0m, in \u001B[0;36mread_csv\u001B[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001B[0m\n\u001B[1;32m   1013\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[1;32m   1014\u001B[0m     dialect,\n\u001B[1;32m   1015\u001B[0m     delimiter,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1022\u001B[0m     dtype_backend\u001B[38;5;241m=\u001B[39mdtype_backend,\n\u001B[1;32m   1023\u001B[0m )\n\u001B[1;32m   1024\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[0;32m-> 1026\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Python/3.9/site-packages/pandas/io/parsers/readers.py:620\u001B[0m, in \u001B[0;36m_read\u001B[0;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[1;32m    617\u001B[0m _validate_names(kwds\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnames\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[1;32m    619\u001B[0m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[0;32m--> 620\u001B[0m parser \u001B[38;5;241m=\u001B[39m \u001B[43mTextFileReader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    622\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[1;32m    623\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "File \u001B[0;32m/Library/Python/3.9/site-packages/pandas/io/parsers/readers.py:1620\u001B[0m, in \u001B[0;36mTextFileReader.__init__\u001B[0;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[1;32m   1617\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m kwds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m   1619\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles: IOHandles \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m-> 1620\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_engine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Python/3.9/site-packages/pandas/io/parsers/readers.py:1880\u001B[0m, in \u001B[0;36mTextFileReader._make_engine\u001B[0;34m(self, f, engine)\u001B[0m\n\u001B[1;32m   1878\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m mode:\n\u001B[1;32m   1879\u001B[0m         mode \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m-> 1880\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;241m=\u001B[39m \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1881\u001B[0m \u001B[43m    \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1882\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1883\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1884\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcompression\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1885\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmemory_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmemory_map\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1886\u001B[0m \u001B[43m    \u001B[49m\u001B[43mis_text\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_text\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1887\u001B[0m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding_errors\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstrict\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1888\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstorage_options\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1889\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1890\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1891\u001B[0m f \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles\u001B[38;5;241m.\u001B[39mhandle\n",
      "File \u001B[0;32m/Library/Python/3.9/site-packages/pandas/io/common.py:873\u001B[0m, in \u001B[0;36mget_handle\u001B[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[1;32m    868\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[1;32m    869\u001B[0m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[1;32m    870\u001B[0m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[1;32m    871\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mencoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mmode:\n\u001B[1;32m    872\u001B[0m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[0;32m--> 873\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[1;32m    874\u001B[0m \u001B[43m            \u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    875\u001B[0m \u001B[43m            \u001B[49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    876\u001B[0m \u001B[43m            \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    877\u001B[0m \u001B[43m            \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    878\u001B[0m \u001B[43m            \u001B[49m\u001B[43mnewline\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    879\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    880\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    881\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[1;32m    882\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(handle, ioargs\u001B[38;5;241m.\u001B[39mmode)\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'sp500_weights_2019_2024.csv'"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb844071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_date</th>\n",
       "      <th>w_added</th>\n",
       "      <th>w_deleted</th>\n",
       "      <th>delta_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-06-21</td>\n",
       "      <td>0.003804</td>\n",
       "      <td>0.004545</td>\n",
       "      <td>-0.000742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-09-20</td>\n",
       "      <td>0.004127</td>\n",
       "      <td>0.004578</td>\n",
       "      <td>-0.000451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-12-20</td>\n",
       "      <td>0.006074</td>\n",
       "      <td>0.004595</td>\n",
       "      <td>0.001480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-03-20</td>\n",
       "      <td>0.002111</td>\n",
       "      <td>0.001203</td>\n",
       "      <td>0.000908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-06-19</td>\n",
       "      <td>0.004184</td>\n",
       "      <td>0.004797</td>\n",
       "      <td>-0.000613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   event_date   w_added  w_deleted  delta_weight\n",
       "0  2019-06-21  0.003804   0.004545     -0.000742\n",
       "1  2019-09-20  0.004127   0.004578     -0.000451\n",
       "2  2019-12-20  0.006074   0.004595      0.001480\n",
       "3  2020-03-20  0.002111   0.001203      0.000908\n",
       "4  2020-06-19  0.004184   0.004797     -0.000613"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ========= 3. Compute ΔW (delta_weight) from weights =========\n",
    "\n",
    "def compute_delta_weight_from_weights(\n",
    "    weights_daily: pd.DataFrame,\n",
    "    events: pd.DataFrame,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Given daily S&P500 weights and a list of rebalance event_dates,\n",
    "    compute:\n",
    "        w_added   = sum of weights of names added between prev and this rebalance\n",
    "        w_deleted = sum of weights of names deleted\n",
    "        delta_weight = w_added - w_deleted\n",
    "\n",
    "    We assume:\n",
    "       weights_daily columns: ['date', 'permno', 'ticker', 'weight']\n",
    "       events columns: ['event_date', ...]\n",
    "    \"\"\"\n",
    "    w = weights_daily.copy()\n",
    "    w[\"date\"] = pd.to_datetime(w[\"date\"]).dt.date\n",
    "\n",
    "    ev = events.sort_values(\"event_date\").reset_index(drop=True)\n",
    "\n",
    "    records = []\n",
    "    for i in range(1, len(ev)):\n",
    "        prev_date = ev.loc[i - 1, \"event_date\"]\n",
    "        this_date = ev.loc[i, \"event_date\"]\n",
    "\n",
    "        w_prev = w[w[\"date\"] == prev_date]\n",
    "        w_this = w[w[\"date\"] == this_date]\n",
    "\n",
    "        # If either date is missing from the weights (e.g. before 2019), skip\n",
    "        if w_prev.empty or w_this.empty:\n",
    "            continue\n",
    "\n",
    "        prev_ids = set(w_prev[\"permno\"])\n",
    "        this_ids = set(w_this[\"permno\"])\n",
    "\n",
    "        added_ids   = this_ids - prev_ids\n",
    "        deleted_ids = prev_ids - this_ids\n",
    "\n",
    "        w_added   = w_this.loc[w_this[\"permno\"].isin(added_ids), \"weight\"].sum()\n",
    "        w_deleted = w_prev.loc[w_prev[\"permno\"].isin(deleted_ids), \"weight\"].sum()\n",
    "        delta_w   = float(w_added - w_deleted)\n",
    "\n",
    "        records.append(\n",
    "            {\n",
    "                \"event_date\": this_date,\n",
    "                \"w_added\": float(w_added),\n",
    "                \"w_deleted\": float(w_deleted),\n",
    "                \"delta_weight\": delta_w,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "\n",
    "deltaW_df = compute_delta_weight_from_weights(weights_df, events_df)\n",
    "deltaW_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d504513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_date</th>\n",
       "      <th>w_added</th>\n",
       "      <th>w_deleted</th>\n",
       "      <th>delta_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-06-21</td>\n",
       "      <td>0.003804</td>\n",
       "      <td>0.004545</td>\n",
       "      <td>-0.000742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-09-20</td>\n",
       "      <td>0.004127</td>\n",
       "      <td>0.004578</td>\n",
       "      <td>-0.000451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-12-20</td>\n",
       "      <td>0.006074</td>\n",
       "      <td>0.004595</td>\n",
       "      <td>0.001480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-03-20</td>\n",
       "      <td>0.002111</td>\n",
       "      <td>0.001203</td>\n",
       "      <td>0.000908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-06-19</td>\n",
       "      <td>0.004184</td>\n",
       "      <td>0.004797</td>\n",
       "      <td>-0.000613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   event_date   w_added  w_deleted  delta_weight\n",
       "0  2019-06-21  0.003804   0.004545     -0.000742\n",
       "1  2019-09-20  0.004127   0.004578     -0.000451\n",
       "2  2019-12-20  0.006074   0.004595      0.001480\n",
       "3  2020-03-20  0.002111   0.001203      0.000908\n",
       "4  2020-06-19  0.004184   0.004797     -0.000613"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ========= 4. Merge ΔW into events_df and align with ES sample =========\n",
    "\n",
    "# merge\n",
    "events_df = events_df.merge(\n",
    "    deltaW_df[[\"event_date\", \"w_added\", \"w_deleted\", \"delta_weight\"]],\n",
    "    on=\"event_date\",\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "# make ES index a DatetimeIndex (if not already) and compute log returns\n",
    "es_df_ev = es_df.copy()\n",
    "if not isinstance(es_df_ev.index, pd.DatetimeIndex):\n",
    "    es_df_ev.index = pd.to_datetime(es_df_ev.index)\n",
    "\n",
    "es_df_ev = es_df_ev.sort_index()\n",
    "es_df_ev[\"log_ret\"] = np.log(es_df_ev[\"close\"]).diff()\n",
    "es_df_ev = es_df_ev.dropna(subset=[\"log_ret\"])\n",
    "\n",
    "# keep only events that lie inside the ES sample and have delta_weight\n",
    "min_es_date = es_df_ev.index.min().date()\n",
    "max_es_date = es_df_ev.index.max().date()\n",
    "\n",
    "events_df = events_df[\n",
    "    (events_df[\"event_date\"] >= min_es_date)\n",
    "    & (events_df[\"event_date\"] <= max_es_date)\n",
    "]\n",
    "events_df = events_df.dropna(subset=[\"delta_weight\"]).reset_index(drop=True)\n",
    "\n",
    "events_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9471e58d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_date</th>\n",
       "      <th>date</th>\n",
       "      <th>rel_day</th>\n",
       "      <th>log_ret</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-06-21</td>\n",
       "      <td>2019-06-16</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.001296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-06-21</td>\n",
       "      <td>2019-06-17</td>\n",
       "      <td>-4</td>\n",
       "      <td>-0.001210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-06-21</td>\n",
       "      <td>2019-06-18</td>\n",
       "      <td>-3</td>\n",
       "      <td>0.011090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-06-21</td>\n",
       "      <td>2019-06-19</td>\n",
       "      <td>-2</td>\n",
       "      <td>0.004265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-06-21</td>\n",
       "      <td>2019-06-20</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.005687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   event_date        date  rel_day   log_ret\n",
       "0  2019-06-21  2019-06-16       -5  0.001296\n",
       "1  2019-06-21  2019-06-17       -4 -0.001210\n",
       "2  2019-06-21  2019-06-18       -3  0.011090\n",
       "3  2019-06-21  2019-06-19       -2  0.004265\n",
       "4  2019-06-21  2019-06-20       -1  0.005687"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ========= 5. Build event windows around each rebalance =========\n",
    "\n",
    "def build_event_windows(\n",
    "    es_with_ret: pd.DataFrame,\n",
    "    events: pd.DataFrame,\n",
    "    k: int,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Build a panel of ES log returns in [-k, +k] trading days around\n",
    "    each event_date.\n",
    "\n",
    "    Returns DataFrame with columns:\n",
    "        event_date, date, rel_day, log_ret\n",
    "    \"\"\"\n",
    "    es = es_with_ret.copy()\n",
    "    if not isinstance(es.index, pd.DatetimeIndex):\n",
    "        es.index = pd.to_datetime(es.index)\n",
    "    es = es.sort_index()\n",
    "\n",
    "    records = []\n",
    "\n",
    "    for _, row in events.iterrows():\n",
    "        ed = pd.to_datetime(row[\"event_date\"])\n",
    "        if ed not in es.index:\n",
    "            # if exact date missing (e.g., holiday), skip\n",
    "            continue\n",
    "\n",
    "        center_idx = es.index.get_loc(ed)\n",
    "        # get_loc might return slice if duplicates, but ES daily shouldn't\n",
    "        if isinstance(center_idx, slice):\n",
    "            center_idx = center_idx.start\n",
    "\n",
    "        start_idx = max(center_idx - k, 0)\n",
    "        end_idx   = min(center_idx + k, len(es) - 1)\n",
    "\n",
    "        window = es.iloc[start_idx : end_idx + 1].copy()\n",
    "        rel_days = np.arange(start_idx - center_idx, end_idx - center_idx + 1)\n",
    "\n",
    "        tmp = pd.DataFrame(\n",
    "            {\n",
    "                \"event_date\": row[\"event_date\"],\n",
    "                \"date\": window.index.date,\n",
    "                \"rel_day\": rel_days,\n",
    "                \"log_ret\": window[\"log_ret\"].values,\n",
    "            }\n",
    "        )\n",
    "        records.append(tmp)\n",
    "\n",
    "    if records:\n",
    "        ev_panel = pd.concat(records, ignore_index=True)\n",
    "    else:\n",
    "        ev_panel = pd.DataFrame(columns=[\"event_date\", \"date\", \"rel_day\", \"log_ret\"])\n",
    "\n",
    "    return ev_panel\n",
    "\n",
    "\n",
    "event_panel = build_event_windows(es_df_ev, events_df, CFG.event_window_k)\n",
    "event_panel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b90771f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mu': 0.00046448776843575917, 'sigma': 0.010755261352675833}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ========= 6. Baseline & abnormal returns, CAR =========\n",
    "\n",
    "def compute_baseline_and_ar(\n",
    "    es_with_ret: pd.DataFrame,\n",
    "    event_panel: pd.DataFrame,\n",
    "    k: int,\n",
    "):\n",
    "    \"\"\"\n",
    "    Baseline: ES log_return mean & std on days NOT in any event window.\n",
    "    AR: log_ret - baseline_mean\n",
    "    CAR: cumulative AR per event over rel_day.\n",
    "    \"\"\"\n",
    "    es = es_with_ret.copy()\n",
    "    if not isinstance(es.index, pd.DatetimeIndex):\n",
    "        es.index = pd.to_datetime(es.index)\n",
    "\n",
    "    window_dates = pd.to_datetime(event_panel[\"date\"].unique())\n",
    "    mask = es.index.isin(window_dates)\n",
    "    baseline_ret = es.loc[~mask, \"log_ret\"]\n",
    "\n",
    "    mu = baseline_ret.mean()\n",
    "    sigma = baseline_ret.std(ddof=1)\n",
    "\n",
    "    ev = event_panel.copy()\n",
    "    ev[\"ar\"] = ev[\"log_ret\"] - mu\n",
    "    ev[\"car\"] = ev.groupby(\"event_date\")[\"ar\"].cumsum()\n",
    "\n",
    "    baseline_stats = {\"mu\": mu, \"sigma\": sigma}\n",
    "    return ev, baseline_stats\n",
    "\n",
    "\n",
    "event_panel, baseline_stats = compute_baseline_and_ar(\n",
    "    es_df_ev, event_panel, CFG.event_window_k\n",
    ")\n",
    "\n",
    "baseline_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a8fe251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_date</th>\n",
       "      <th>window_vol</th>\n",
       "      <th>baseline_vol</th>\n",
       "      <th>vol_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-06-21</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.010755</td>\n",
       "      <td>0.516597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-09-20</td>\n",
       "      <td>0.004369</td>\n",
       "      <td>0.010755</td>\n",
       "      <td>0.406231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-12-20</td>\n",
       "      <td>0.002073</td>\n",
       "      <td>0.010755</td>\n",
       "      <td>0.192756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-03-20</td>\n",
       "      <td>0.053575</td>\n",
       "      <td>0.010755</td>\n",
       "      <td>4.981288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-06-19</td>\n",
       "      <td>0.023188</td>\n",
       "      <td>0.010755</td>\n",
       "      <td>2.156008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   event_date  window_vol  baseline_vol  vol_ratio\n",
       "0  2019-06-21    0.005556      0.010755   0.516597\n",
       "1  2019-09-20    0.004369      0.010755   0.406231\n",
       "2  2019-12-20    0.002073      0.010755   0.192756\n",
       "3  2020-03-20    0.053575      0.010755   4.981288\n",
       "4  2020-06-19    0.023188      0.010755   2.156008"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ========= 7. Volatility diagnostics (optional but useful) =========\n",
    "\n",
    "def compute_vol_volumetrics(\n",
    "    event_panel: pd.DataFrame,\n",
    "    baseline_stats: dict,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For each event, compute realized volatility of ES log returns\n",
    "    inside the event window and compare to baseline sigma.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for ed, grp in event_panel.groupby(\"event_date\"):\n",
    "        win_vol = grp[\"log_ret\"].std(ddof=1)\n",
    "        rows.append(\n",
    "            {\n",
    "                \"event_date\": ed,\n",
    "                \"window_vol\": win_vol,\n",
    "                \"baseline_vol\": baseline_stats[\"sigma\"],\n",
    "                \"vol_ratio\": win_vol / baseline_stats[\"sigma\"] if baseline_stats[\"sigma\"] != 0 else np.nan,\n",
    "            }\n",
    "        )\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "vol_stats = compute_vol_volumetrics(event_panel, baseline_stats)\n",
    "vol_stats.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70177b5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_date</th>\n",
       "      <th>entry_date</th>\n",
       "      <th>exit_date</th>\n",
       "      <th>entry_px</th>\n",
       "      <th>exit_px</th>\n",
       "      <th>pnl_points</th>\n",
       "      <th>pnl_dollars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-06-21</td>\n",
       "      <td>2019-06-18</td>\n",
       "      <td>2019-06-21</td>\n",
       "      <td>2924.25</td>\n",
       "      <td>2951.50</td>\n",
       "      <td>27.25</td>\n",
       "      <td>1362.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-09-20</td>\n",
       "      <td>2019-09-17</td>\n",
       "      <td>2019-09-20</td>\n",
       "      <td>3004.25</td>\n",
       "      <td>3013.75</td>\n",
       "      <td>9.50</td>\n",
       "      <td>475.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-12-20</td>\n",
       "      <td>2019-12-17</td>\n",
       "      <td>2019-12-20</td>\n",
       "      <td>3190.75</td>\n",
       "      <td>3219.25</td>\n",
       "      <td>28.50</td>\n",
       "      <td>1425.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-03-20</td>\n",
       "      <td>2020-03-17</td>\n",
       "      <td>2020-03-20</td>\n",
       "      <td>2425.25</td>\n",
       "      <td>2445.00</td>\n",
       "      <td>19.75</td>\n",
       "      <td>987.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-06-19</td>\n",
       "      <td>2020-06-16</td>\n",
       "      <td>2020-06-19</td>\n",
       "      <td>3135.50</td>\n",
       "      <td>3196.00</td>\n",
       "      <td>60.50</td>\n",
       "      <td>3025.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   event_date  entry_date   exit_date  entry_px  exit_px  pnl_points  \\\n",
       "0  2019-06-21  2019-06-18  2019-06-21   2924.25  2951.50       27.25   \n",
       "1  2019-09-20  2019-09-17  2019-09-20   3004.25  3013.75        9.50   \n",
       "2  2019-12-20  2019-12-17  2019-12-20   3190.75  3219.25       28.50   \n",
       "3  2020-03-20  2020-03-17  2020-03-20   2425.25  2445.00       19.75   \n",
       "4  2020-06-19  2020-06-16  2020-06-19   3135.50  3196.00       60.50   \n",
       "\n",
       "   pnl_dollars  \n",
       "0       1362.5  \n",
       "1        475.0  \n",
       "2       1425.0  \n",
       "3        987.5  \n",
       "4       3025.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ========= 8. Simple ES strategy around rebalances (optional) =========\n",
    "\n",
    "def backtest_rebalance_strategy(\n",
    "    es_with_ret: pd.DataFrame,\n",
    "    events: pd.DataFrame,\n",
    "    k_entry: int,\n",
    "    contract_mult: int,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Very simple strategy:\n",
    "      - Enter 1 ES contract at close k_entry trading days BEFORE event_date\n",
    "      - Exit at close on event_date\n",
    "      - Always long (you can change sign if you want).\n",
    "    \"\"\"\n",
    "    es = es_with_ret.copy()\n",
    "    if not isinstance(es.index, pd.DatetimeIndex):\n",
    "        es.index = pd.to_datetime(es.index)\n",
    "    es = es.sort_index()\n",
    "\n",
    "    trades = []\n",
    "\n",
    "    for _, row in events.iterrows():\n",
    "        ed = pd.to_datetime(row[\"event_date\"])\n",
    "        if ed not in es.index:\n",
    "            continue\n",
    "\n",
    "        center_idx = es.index.get_loc(ed)\n",
    "        if isinstance(center_idx, slice):\n",
    "            center_idx = center_idx.start\n",
    "\n",
    "        entry_idx = center_idx - k_entry\n",
    "        if entry_idx < 0:\n",
    "            continue\n",
    "\n",
    "        entry_date = es.index[entry_idx]\n",
    "        exit_date  = es.index[center_idx]\n",
    "\n",
    "        entry_px = es.loc[entry_date, \"close\"]\n",
    "        exit_px  = es.loc[exit_date, \"close\"]\n",
    "\n",
    "        pnl_points = exit_px - entry_px  # long 1 contract\n",
    "        pnl_dollars = pnl_points * contract_mult\n",
    "\n",
    "        trades.append(\n",
    "            {\n",
    "                \"event_date\": row[\"event_date\"],\n",
    "                \"entry_date\": entry_date.date(),\n",
    "                \"exit_date\": exit_date.date(),\n",
    "                \"entry_px\": float(entry_px),\n",
    "                \"exit_px\": float(exit_px),\n",
    "                \"pnl_points\": float(pnl_points),\n",
    "                \"pnl_dollars\": float(pnl_dollars),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return pd.DataFrame(trades)\n",
    "\n",
    "\n",
    "trades_df = backtest_rebalance_strategy(\n",
    "    es_df_ev, events_df, CFG.strat_k_entry, CFG.contract_multiplier\n",
    ")\n",
    "trades_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20fc7a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    car   R-squared:                       0.009\n",
      "Model:                            OLS   Adj. R-squared:                 -0.039\n",
      "Method:                 Least Squares   F-statistic:                    0.1820\n",
      "Date:                Wed, 03 Dec 2025   Prob (F-statistic):              0.674\n",
      "Time:                        16:54:22   Log-Likelihood:                 48.951\n",
      "No. Observations:                  23   AIC:                            -93.90\n",
      "Df Residuals:                      21   BIC:                            -91.63\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "================================================================================\n",
      "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "const            0.0015      0.008      0.200      0.843      -0.014       0.017\n",
      "delta_weight    -0.7181      1.683     -0.427      0.674      -4.219       2.783\n",
      "==============================================================================\n",
      "Omnibus:                        3.024   Durbin-Watson:                   1.803\n",
      "Prob(Omnibus):                  0.220   Jarque-Bera (JB):                1.400\n",
      "Skew:                          -0.437   Prob(JB):                        0.497\n",
      "Kurtosis:                       3.836   Cond. No.                         268.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_date</th>\n",
       "      <th>car</th>\n",
       "      <th>delta_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-06-21</td>\n",
       "      <td>0.009992</td>\n",
       "      <td>-0.000742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-09-20</td>\n",
       "      <td>-0.014632</td>\n",
       "      <td>-0.000451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-12-20</td>\n",
       "      <td>0.017104</td>\n",
       "      <td>0.001480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-03-20</td>\n",
       "      <td>-0.018521</td>\n",
       "      <td>0.000908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-06-19</td>\n",
       "      <td>0.007086</td>\n",
       "      <td>-0.000613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   event_date       car  delta_weight\n",
       "0  2019-06-21  0.009992     -0.000742\n",
       "1  2019-09-20 -0.014632     -0.000451\n",
       "2  2019-12-20  0.017104      0.001480\n",
       "3  2020-03-20 -0.018521      0.000908\n",
       "4  2020-06-19  0.007086     -0.000613"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ========= 9. Regression of CAR on ΔW =========\n",
    "\n",
    "def run_delta_weight_regression(\n",
    "    event_panel: pd.DataFrame,\n",
    "    events: pd.DataFrame,\n",
    "    horizon_k: int,\n",
    "):\n",
    "    \"\"\"\n",
    "    Regress CAR_{0,+k} on delta_weight.\n",
    "\n",
    "    Returns (model, regression_df).\n",
    "    \"\"\"\n",
    "    ev = event_panel.copy()\n",
    "\n",
    "    # take CAR at rel_day = +k (or last available if shorter window)\n",
    "    target = ev[ev[\"rel_day\"] == horizon_k][[\"event_date\", \"car\"]].copy()\n",
    "\n",
    "    df = target.merge(\n",
    "        events[[\"event_date\", \"delta_weight\"]],\n",
    "        on=\"event_date\",\n",
    "        how=\"inner\",\n",
    "    ).dropna(subset=[\"delta_weight\", \"car\"])\n",
    "\n",
    "    X = sm.add_constant(df[\"delta_weight\"])\n",
    "    y = df[\"car\"]\n",
    "\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    return model, df\n",
    "\n",
    "\n",
    "reg_model, reg_df = run_delta_weight_regression(\n",
    "    event_panel, events_df, CFG.event_window_k\n",
    ")\n",
    "\n",
    "print(reg_model.summary())\n",
    "reg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1b8d37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a031729ff22ef39e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
